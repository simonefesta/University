Una relazione tra il bond al tempo 0 e al tempo T è caratterizzata da: B0 = B(T)/(1+r(T)) dove B0 è prezzo di mercato, B(T) prezzo pagato alla scadenza (valore nominale, sempre noto) e r(T) = tasso di interesse non rischioso per [0,T] = d(T)*B(T) con d(T) tasso di sconto.
La formula di prima è equazione lineare. Cosa è questo r(T), chi lo definisce?
La FED lo definisce per le banche, ma per i risparmiatori chi lo definisce?
Possiamo definirlo mediante regressione lineare, e quindi trovare il coefficiente di una regressione lineare.
Abbiamo parlato di opzioni CALL e PUT, molto importanti.
Hanno la caratteristiche che C(T) = (S(T) - K)^+ = max {S(T)-K,0} = (|S(T) - K| + S(T) - k)/2
P(T) = (K-S(T))^+ = max {K - S(T),0} = (|K - S(T)| + k - S(T))/2

Se ci mettiamo in condizioni di non arbitraggio, possiamo dire che C0 - P0 = S0 - K/(1+r(T)), come ci siamo arrivati?
C(T) - P(T) = S(T) - K, tale relazione è strutturale che non dipende dal modello, ma da come vengono formulate le opzioni call o put (vale quindi per binomiale, continuo, etc..) Tale relazione, se rapportata al tempo 0, ci porta all'equazione di prima al tempo 0. (a parità di call e put, ordinate per k, con stessa scadenza, T deve essere uguale).
Nella tabella avrò T fissato C0(k1) | P0(k1), poichè sto mettendo in relazione due dataset, sto creando un set di equazioni lineari tramite C0 - P0 = S0 - K/(1+r(T))
                             C1(k2) | P1(k2)
per capire chi è r(T) che rende l'equazione il più valida possibile (migliore approssimazione, anche perchè qui assumiamo costi operazionali nulli).
Il rumore di mercato è generato da queste "imperfezioni". Alla fine troveremo qualcosa del tipo C0 - P0 = S0 - K/(1+r(T)) + U, dove U è rumore di mercato.
Questa equazione è del tipo Y = f(x) + U, cioè regressione semplice, che mira a stabilire una relazione tra due v.a. X e Y e in cui interviene un rumore.
Quella trovata da noi C0 - P0 è una regressione lineare, un particolare tipo di regressione, poichè del tipo Y = alfa + beta*X + U. Ottengo anche stima tasso non rischioso, e vedere se è più o meno attendibile.

1 Simple Regression of Real Random Variables: operiamo in uno spazio in cui possiamo calcolare la varianza.
"simple" perchè metto in relazione due v.a. tra loro, U è variabile scorrelata che ha momento del secondo ordine.

1,4 (x,y) sono numeri reali, X e Y v.a. in 1.4 abbiamo curva di regressione.
Posso prendere U con media nulla, altrimenti la shifto. U modella rumore, che mediamente sono nulli. (magari una volta in eccesso, una volta in difetto).
Se misura sempre in eccesso, scarico questo eccesso sulle misure.
U = Y - E[Y|X], media nulla, varianza di U, e soddisfa proposizione 1.1.

La speranza condizionata è ciò che rappresenta meglio la funzione F(X).

example 1.1 Y indipendente da X, in quanto f(X) è indipendente da Y, più rumore, allora questo qualcosa può essere solo la speranza.
f(x) = E[Y] e' costante, cioè la funzione di regressione è costante.

example 1.2. U = 0 e E[Y|X] = Y allora trovo la funzione identica.

example 1.3. ho due v.a. congiuntamente gaussiane, allora la speranza condizionata la scrivo come nell'esempio. conti lunghini, posso andare diretto al risultato. quando ho due v.a. congiuntamente gaussiane, la miglior funzione di regressione è una funzione lineare. La lineare non è solo una forma comoda quindi, perchè nel caso congiuntamente gaussiane, è la forma migliore per esprimere la dipendenza tra loro. A volte la semplicità è la cosa migliore.
Andando avanti non parleremo più di v.a. X, ma di un set di osservazioni indipendenti (campione semplice) tra due set di grandezze, non avrò una equazione tra due v.a. ma tante equazioni tra due dataset.
Tutte le medie e speranze, diventeranno empiriche.
Se due elementi hanno prodotto e somma >0 allora essi sono >0

cap 2 - simple regression of real data sets
scarichiamo queste cose sui dataset. pesco studente a caso (v.a.) ed estraggo un valore. lo faccio per un tot di studenti, misuro altezza e peso a  caso, facendo campionamento semplice causale dell'altezza e del peso. si traduce in due dataset. Sono due campioni, le osservazioni si traducono in due dataset di numeri reali. Con tale modello, il campione aleatorio semplice X1,...,Xn moralmente lo valuto sullo stesso evento aleatorio omega, non sono tanti omega diversi. E' come dire che se pesco 10 studenti, è tutto un evento aleatorio singolare, invece che vederlo come 10 realizzazione indipendenti della v.a. Spesso è difficile trovare funzione perfetta, ma ne cerchiamo una che pesa abbastanza bene, esercitando un controllo sull'errore (sarebbe impossibile trovare una formula che lega altezza e peso).

esempio 2.1
regressione tra due v.a. congiuntamente gaussiane.
parto da due v.a. indip Z1 e Z2 gaussiane std, che caratteristiche ha vettore aleatorio? X e Y saranno congiuntamente gaussiani.
Se introduco le notazioni E[X] = mu etc, applico l'operatore speranza e varianza. Anche il rumore risulta gaussianamente distribuito.
Quindi sono partito da due gauss std, applico la trasformazione matrice + vettore, trovo v.a. X e Y, se ci faccio la regressione trovo coefficienti di regressioni. 

Visto esempio in R.
Fisso dimensione, ne prendo 150. FIsso seme aleatorio, pesco con rnorm 150 valori indipendenti, cosi genero le realizzazioni di una v.a. gauss. std.
anche Z2 uguale, ma fisso seme diverso, per riproducibilità e per essere sicuro che siano indipendenti.
prendo i dataframe (sopratutto per rappresentazione grafica) e vi aggiungo colonna k (sembrano valori doppi ma il primo valore è la riga, il secondo è il valore proprio di k). Tali script sono altamente riusabili. Alla fine trovo due grafici.
Nel dataset z1 trovo retta verde che è la famosa retta di regressione, abbastanza piatta su 0, questo è sintomo di media nulla.
la linea tratteggiata è lowest (o loess?), retta locale /curva locale di regressione fatta "pezzettino per pezzettino", prende le "tendenze locali", e spesso si adagia sulla retta di regressione, quindi le tendenze locali sono casuali e poco significative.
I punti in blu non hanno una concentrazione specifica, è detta "nuvola", non ci sono zone più variabili di altre. "Omoschedasticità".
Tutte queste cose ci danno l'info di trattare "un buon rumore", qui parliamo di white noise gaussiano.

Anche per Z2 sostanzialmente siamo li, non riusciremmo a distinguerla da z1 senza vedere chi è chi. Sono grafici di rumori gaussiani.

alcune conclusioni:
- attraverso questi grafici possiamo pensare che entrambi i dataset siano generati da campionamento indipendente dalla stessa distribuzione, ma non so quale! Spesso posso fare shuffle per vedere se cambia qualcosa, nel nostro esempio la struttura è la stessa, perchè ho usato campionamento indipendentemente, l'indice del campionamento non conta nulla. Nelle serie storiche dove l'indice rappresenta indice temporale, la maggior parte dei casi in cui faccio shuffle distruggo il dataset da cui sono partito.



